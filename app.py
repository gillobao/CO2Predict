# -*- coding: utf-8 -*-
"""
Created on Mon Jan 16 09:55:19 2023

@author: S028171
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from streamlit_shap import st_shap

# Emissions de polluants, CO2 et caract√©ristiques des v√©hicules
# commercialis√©s en France en 2013
df_2013 = pd.read_csv('data_2013.csv' , sep = ';', encoding='unicode_escape')
df_2013_nettoye = pd.read_csv('df_2013_nettoye.csv' , sep = ';', encoding='unicode_escape')
df = pd.read_csv('df.csv', index_col = 0)

    #---------------------------------------------------------------------------------------------------------
    #                                                    Streamlit 
    #---------------------------------------------------------------------------------------------------------

# Affichage de toutes les pages de la pr√©sentation sur toute la largeur de l'√©cran automatiquement:
st.set_page_config(layout="wide")
st.set_option('deprecation.showPyplotGlobalUse', False)


# Sommaire du Sreamlit
## Centrer l'image en haut de la sidebar:
st.markdown(
    """
    <style>
        [data-testid=stSidebar] [data-testid=stImage]{
            text-align: center;
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 100%;
        }
    </style>
    """, unsafe_allow_html=True
)

with st.sidebar:
    st.image('https://www.fiches-auto.fr/sdoms/shiatsu/uploaded/part-effet-de-serre-co2-automobile-2.jpg')
 
## Affichage du titre et du plan dans la sidebar:
st.sidebar.title('Projet CO2 Predict')    
pages = ['Accueil','Introduction','Exploration et analyse des donn√©es', 
         'Mod√©lisation : R√©gression multiple', 'Mod√©lisation : Classification', 'Interpr√©tabilit√© SHAP multi-classes', 
         "Pr√©dictions : Algorithme 'CO‚ÇÇ Predict'", 'Conclusion']

st.sidebar.markdown('**Sommaire**')
page = st.sidebar.radio('', pages)

## Affichage des auteurs et mentor en bas de la sidebar:
st.sidebar.write(' ')
st.sidebar.write(' ')
st.sidebar.write(' ')
st.sidebar.write(' ')
st.sidebar.write('### Auteurs:')
st.sidebar.write('Camille Millon')
st.sidebar.write('Gilles Ngamenye')
st.sidebar.write('Christophe Seuret')
st.sidebar.write(' ')
st.sidebar.write('### Mentor:')
st.sidebar.write('Dan Cohen')



#Chargement des datasets---------------------------------------------------

# Emissions de polluants, CO2 et caract√©ristiques des v√©hicules
# commercialis√©s en France en 2013
df_2013 = pd.read_csv('data_2013.csv' , sep = ';', encoding='unicode_escape')
data = pd.read_csv('data.csv', index_col = 0)
target_reg = pd.read_csv('target_reg.csv', index_col = 0)
target_reg = target_reg.squeeze()



#------------------------------------  Page 0 : accueil ----------------------------------------------------
if page == pages[0]:
    from PIL import Image
    st.image(Image.open('CO2 predict1.png'))


#------------------------------------  Page 1 : introduction ----------------------------------------------------
if page == pages[1]:
    st.write('### Introduction au projet')
    
    st.write('###### Objectifs :  \n- Identifier les v√©hicules qui √©mettent le plus de CO2 est important pour identifier les caract√©ristiques techniques qui jouent un r√¥le dans la pollution.  \n- Pr√©dire √† l‚Äôavance cette pollution permet de pr√©venir dans le cas de l‚Äôapparition de nouveaux types de v√©hicules (nouvelles s√©ries de voitures par exemple')
    st.markdown('Le projet est effectu√© √† partir du dataset regroupant les √©missions de CO2 et polluants des v√©hicules commercialis√©es en France en 2013')
    st.markdown('[Source du dataset]( https://www.data.gouv.fr/fr/datasets/emissions-de-co2-et-de-polluants-des-vehicules-commercialises-en-france/#_)')
       
    st.write('### Visualisation du dataset')
    st.dataframe(df_2013.head())
    

#------------------------------------  Page 2 : exploration des donn√©es ---------------------------------------------

if page == pages[2]:
    st.write('## Exploration et analyse des donn√©es')
    

    tab1, tab2, tab3 = st.tabs(['Variables du dataset', 'Preprocessing', 'Liens entre variables'])
    
    with tab1:
 
        st.write('Deux types de variables sont disponibles : 13 qualitatives et 13 quantitatives')
        st.write('Le dataset de d√©part contient 44 850 lignes')
        #st.caption('Certaines variables sont redondantes (color√©es de la m√™me fa√ßon ci-dessous)')

        st.write('### Variables du dataset')
 
   
        var_num_2013 = df_2013.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
        var_cat_2013 = df_2013.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles

        tab_num=pd.DataFrame(var_num_2013.columns,columns=['Quantitatives'])
        tab_cat=pd.DataFrame(var_cat_2013.columns,columns=['Qualitatives'])
    
    # table pour pr√©senter les donn√©es qualitatives et quantitatives
        table1 = pd.concat([tab_num,tab_cat],axis=1).fillna('')
    
       #on d√©finit des couleurs identiques poru les variables semblables
        def couleur1(val):
           color='white' #if val not in ('Mod√®le UTAC' 'Mod√®le dossier' 'D√©signation commerciale') else 'paleturquoise'
           return 'background-color:%s' % color

     
    # code pour masquer les index
        hide_table_row_index = """
            <style>
            thead tr th:first-child {display:none}
            tbody th {display:none}
            </style>
            """
    # Inject CSS with Markdown
        st.markdown(hide_table_row_index, unsafe_allow_html=True)

    # Display a static table
        st.table(table1.style.applymap(couleur1))



    with tab2:
        
        st.write('**Etapes du preprocessing :**')
        st.write('- Suppression des doublons (619)')
        st.write('- Traitement des valeurs manquantes : concerne uniquement les variables quantitatives, remplacement par les moyennes des valeurs non manquantes')
        st.write('- Suppression des modalit√©s sous-repr√©sent√©es :')
        

        fig1=px.histogram(df_2013,x="Carburant",color = 'Carburant',color_discrete_sequence=px.colors.qualitative.Pastel)
        fig1.update_layout(title_text='Variable "Carburant" avant preprocessing', title_x=0.5)
        fig1.update_xaxes(categoryorder='total descending')
        
        fig2=px.histogram(df,x="Carburant",color = 'Carburant',color_discrete_sequence=px.colors.qualitative.Pastel) 
        fig2.update_layout(title_text='Variable "Carburant" apr√®s preprocessing', title_x=0.5,yaxis_range=[0,40000])
        fig2.update_xaxes(categoryorder='total descending')
        
        data_container=st.container()
        with data_container:
            commentaires,plot1, plot2 = st.columns([0.5,1,1])
            with commentaires:
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write('La variable carburant poss√®de un grand nombre de modalit√©s."Essence (ES)" et "Gasole (GO)" repr√©sentent plus de 99 % du portefeuille, on ne conserve donc que ces deux modalit√©s ')
            with plot1:
                st.plotly_chart(fig1, use_container_width=True)
            with plot2:
                st.plotly_chart(fig2, use_container_width=True)

        df_2013[['boite', 'rapport']]=df_2013['Bo√Æte de vitesse'].str.split(expand=True)
        fig3=px.histogram(df_2013,x='boite',color = 'boite',color_discrete_sequence=px.colors.qualitative.Pastel)
        fig3.update_layout(title_text='Variable "boite" avant preprocessing', title_x=0.5)
        fig3.update_xaxes(categoryorder='total descending')
    
        fig4=px.histogram(df,x="boite",color = 'boite',color_discrete_sequence=['MediumTurquoise','Plum'])
        fig4.update_layout(title_text='Variable "boite" apr√®s preprocessing', title_x=0.5,yaxis_range=[0,25000])
        fig4.update_xaxes(categoryorder='total ascending')
    
        data_container=st.container()
        with data_container:
            commentaires,plot3, plot4 = st.columns([0.5,1,1])
            with commentaires:
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write(' ')
                st.write('M√™me constat pour la variable "boite", sur laquelle seules les modalit√©s "A" (Automatique) et "M" (Manuelle) sont conserv√©es ')

                with plot3:
                    st.plotly_chart(fig3, use_container_width=True)
                with plot4:
                    st.plotly_chart(fig4, use_container_width=True)
  
        st.markdown(hide_table_row_index, unsafe_allow_html=True)
        st.write('- S√©lection des variables utiles')
        

        data_container=st.container()
        with data_container:
            commentaires,image= st.columns([0.5,1])
            with commentaires:
                st.write("- Cr√©ation d'une variable Cat_CO2 discr√®te issue de CO2 sur la base des normes suivantes:")       
            with image:
                from PIL import Image
                image0 = Image.open('etiquette-energie-voiture.jpg')
                st.image(image0,caption='',width=300)
    
        st.write('- Suppression des doublons suite aux premiers traitements (restent 5 020 lignes)')
        st.write('- La base apr√®s preprocessing est la suivante (les variables CO2 et Cat_CO2 sont les variables √† expliquer):')
       #on d√©finit des couleurs identiques poru les variables semblables

        st.dataframe(df.head())


    with tab3:
        graphe_avant,graphe_apres= st.columns([1,0.8])
        with graphe_avant:
            st.write('Matrice de corr√©lation avant preprocessing:')
            fig0, ax0 = plt.subplots(figsize = (3, 3))
            # get label text
            sns.set(font_scale=0.3)
            yticks, ylabels = plt.yticks()
            xticks, xlabels = plt.xticks()
            ax0.set_xticklabels(xlabels, size = 3)
            ax0.set_yticklabels(ylabels, size = 3)
            sns.heatmap(df_2013.corr(), annot = True, ax = ax0, cmap = 'magma');
            st.pyplot(fig0)
                  
            
        with graphe_apres:
            st.write('Matrice de corr√©lation apr√®s preprocessing:')
            fig1, ax1 = plt.subplots(figsize = (3, 3))
            sns.set(font_scale=1)
            ax1=sns.set_context("paper", rc={"font.size":8,"axes.titlesize":15,"axes.labelsize":5}) 
            sns.heatmap(df.corr(), annot = True, ax = ax1, cmap = 'magma');
            st.pyplot(fig1)
        
        #with graphe:
        #   fig, ax = plt.subplots(figsize = (2, 2))
        #   var2=df.drop(['Cat_CO2','Marque','Carburant','Carrosserie','boite','gamme2'],axis=1)
        #    st.write(var2.head())
        #    sns.pairplot(data = var2,
        #     x_vars = var2.columns,
        #     y_vars = var2.columns)
        #    plt.title('Graphique matriciel')
        #    st.pyplot(fig)

#_______________________________________________________________________________________________________
#
#                                   Page 3 : r√©gression 
#_______________________________________________________________________________________________________

#CHARGEMENT DES LIBRAIRIES: ----------------------------------------------------------------------------
import itertools

## Les diff√©rents types de mod√®les de Machine Learning
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectFromModel

## Les fonctions de param√©trage de la mod√©lisation
from sklearn.model_selection import train_test_split, KFold, cross_validate
from sklearn.model_selection import GridSearchCV

## Les fonctions de preprocessing
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder,OneHotEncoder

## Les fonctions statistiques
import scipy.stats as stats

import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

## Les m√©triques
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate
from scipy.stats import jarque_bera

## Les fonctions de sauvegarde et chargement de mod√®les
from joblib import dump, load


from sklearn.model_selection import train_test_split

import matplotlib as mpl





# CHARGEMENT DES JEUX DE DONNEES NETTOYES ET DES TARGETS CORRESPONDANTES: ----------------------------------------------------------------------------
data_go = pd.read_csv('data_go.csv', index_col = 0)
target_go = pd.read_csv('target_go.csv', index_col = 0)
target_go = target_go.squeeze()

data_es = pd.read_csv('data_es.csv', index_col = 0)
target_es = pd.read_csv('target_es.csv', index_col = 0)
target_es = target_es.squeeze()

df = pd.read_csv('df.csv', index_col = 0)
df.CO2 = target_reg



# FONCTIONS: ----------------------------------------------------------------------------

def standardisation_lr(data, target_reg):
    # S√©paration du jeu de donn√©es en un jeu d'entrainement et de test:
    X_train, X_test, y_train, y_test = train_test_split(data, target_reg, random_state = 123, test_size = 0.2)
    
    #Standardisation des valeurs num√©riques + variables 'Marque' (beaucoup de cat√©gories (>10)):
    cols = ['puiss_max', 'masse_ordma_min', 'Marque']
    sc = StandardScaler()
    X_train[cols] = sc.fit_transform(X_train[cols])
    X_test[cols] = sc.transform(X_test[cols])
      
    return [X_train, X_test, y_train, y_test]

def regression_lineaire(model_joblib, X_train, y_train, X_test, y_test):
    # Chargement du mod√®le de r√©gression lin√©aire:
    lr = load(model_joblib)
    
    # Entra√Ænement et pr√©dictions:

    pred_train = lr.predict(X_train) # = valeurs ajust√©es X_train
    pred_test = lr.predict(X_test) # = valeurs ajust√©es X_test
    
    return [lr, pred_train, pred_test]

def selecteur(X_train, y_train, X_test, y_test):
    # Instanciation d'un mod√®le de r√©gression lin√©aire
    lr_sfm = LinearRegression()
    
    # Cr√©ation d'un s√©lecteur √† partir de lr:
    sfm = SelectFromModel(lr_sfm)
    
    # Entrainement du selecteur et sauvegarde des colonnes de X_train s√©lectionn√©es par sfm dans sfm_train:
    sfm_train = pd.DataFrame(sfm.fit_transform(X_train, y_train), index = X_train.index)
    sfm_train = X_train[X_train.columns[sfm.get_support()]]
    
    # Sauvegarde des colonnes de X_test dans sfm_test:
    sfm_test = sfm.transform(X_test)
    sfm_test = X_test[X_test.columns[sfm.get_support()]]
        
    # R√©gression lin√©aire avec sfm_train:
    lr_sfm.fit(sfm_train, y_train)
    pred_train = lr_sfm.predict(sfm_train) # = valeurs ajust√©es sfm_train
    pred_test = lr_sfm.predict(sfm_test) # = valeurs ajust√©es sfm_test
    
    return [lr_sfm, pred_train, pred_test, sfm_train, sfm_test]

def metrics_sfm(lr_sfm, X_train, y_train, X_test, y_test, pred_train, pred_test, sfm_train, sfm_test):
    # Affichage des metrics:
    residus = pred_train - y_train 
    residus_std = residus/np.sqrt(np.sum(residus**2)/(len(residus)-1))
    x, pval = jarque_bera(residus_std)
    st.write('p_value test de normalit√© de Jarque-Bera: =', round(pval,2)) 
    st.write("")
    st.write("R¬≤ train =", round(lr_sfm.score(sfm_train, y_train),2))
    st.write("R¬≤ obtenu par CV =", round(cross_val_score(lr_sfm,sfm_train,y_train).mean(),2))
    st.write("R¬≤ test =", round(lr_sfm.score(sfm_test, y_test),2))
    st.write("")
    st.write('RMSE train =', round(np.sqrt(mean_squared_error(y_train, pred_train)),2))
    st.write('RMSE test =', round(np.sqrt(mean_squared_error(y_test, pred_test)),2))
    st.write("")
    st.write("MAE train:", round(mean_absolute_error(y_train, pred_train),2))
    st.write("MAE test:", round(mean_absolute_error(y_test, pred_test),2))


def metrics_lr(lr, X_train, y_train, X_test, y_test, pred_train, pred_test):
    # Affichage des metrics:
    residus = pred_train - y_train 
    residus_std = residus/np.sqrt(np.sum(residus**2)/(len(residus)-1))
    x, pval = jarque_bera(residus_std)
    st.write('p_value test de normalit√© de Jarque-Bera: =', round(pval,2)) 
    st.write("")
    st.write("R¬≤ train =", round(lr.score(X_train, y_train),2))
    st.write("R¬≤ obtenu par CV =", round(cross_val_score(lr,X_train,y_train, cv = 5).mean(),2))
    st.write("R¬≤ test =", round(lr.score(X_test, y_test),2))
    st.write("")
    st.write('RMSE train =', round(np.sqrt(mean_squared_error(y_train, pred_train)),2))
    st.write('RMSE test =', round(np.sqrt(mean_squared_error(y_test, pred_test)),2))
    st.write("")
    st.write("MAE train:", round(mean_absolute_error(y_train, pred_train),2))
    st.write("MAE test:", round(mean_absolute_error(y_test, pred_test),2))
    
def coef_lr(lr, X_train):
    # Repr√©sentation des coefficients:
    plt.rcParams['axes.facecolor'] = 'whitesmoke'
    
    coef = lr.coef_
    fig = plt.figure()
    plt.bar(X_train.columns, coef)
    plt.xticks(X_train.columns, rotation = 90)
    st.pyplot(fig)

def coef_sfm(lr_sfm, sfm_train):
    # Repr√©sentation des coefficients:
    
    plt.rcParams['axes.facecolor'] = 'whitesmoke'
    if sfm_train.shape[1] >= 1:
        fig = plt.figure()
        coef = lr_sfm.coef_
        fig = plt.figure()
        plt.bar(sfm_train.columns, coef)
        plt.xticks(sfm_train.columns, rotation = 90)
        st.pyplot(fig)

def graph_res(y_train, y_test, pred_train, pred_test):
    #Normalit√© des r√©sidus:
    ## Calcul des r√©sidus et r√©sidus normalis√©s:
    residus = pred_train - y_train 
    residus_norm = (residus-residus.mean())/residus.std()
    residus_std = residus/np.sqrt(np.sum(residus**2)/(len(residus)-1))
          
    # Graphes :
    fig = plt.figure(figsize = (15,10))
    # Espacement des graphes:
    plt.subplots_adjust(left=0.1,
                        bottom=0.1,
                        right=0.9,
                        top=0.9,
                        wspace=0.2,
                        hspace=0.4)
    
    plt.rcParams['axes.facecolor'] = 'whitesmoke'
    
    ## Graphe normalisation r√©sidus:
    plt.subplot(2,2,1)
    stats.probplot(residus_norm, plot = plt)
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    
    ## Graphe r√©sidus en fonction de pred_train (valeurs ajust√©es):
    plt.subplot(2,2,2)
    plt.scatter(pred_train, residus, alpha = 0.3)
    plt.plot((pred_train.min(), pred_train.max()), (0, 0), lw=3, color='red')
    plt.plot((pred_train.min(), pred_train.max()), (2*residus.std(), 2*residus.std()), 'r-', lw=1.5, label = '¬± 2 œÉ') 
    plt.plot((pred_train.min(), pred_train.max()), (3*residus.std(), 3*residus.std()), 'r--', lw=1.5, label = '¬± 3 œÉ')
    plt.plot((pred_train.min(), pred_train.max()), (-2*residus.std(), -2*residus.std()), 'r-',lw=1.5)
    plt.plot((pred_train.min(), pred_train.max()), (-3*residus.std(), -3*residus.std()), 'r--', lw=1.5)
    plt.title('R√©sidus en fonction de pred_train (valeurs ajust√©es)')
    plt.xlabel('pred_train (valeurs ajust√©es)')
    plt.ylabel('R√©sidus')
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.legend(loc = 'lower left')
    
    ## Graphe boxplot des r√©sidus:
    plt.subplot(2,2,3)
    sns.boxplot(residus, notch=True)
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.title('Boite √† moustache des r√©sidus')
    plt.xlabel('r√©sidus')
    
    ## Graphe pr√©dictions en fonction de y_test (= le long de la droite si elles sont bonnes):
    plt.subplot(2,2,4)
    plt.scatter(pred_test, y_test, alpha = 0.3)
    plt.title('Nuage de points entre pred_test et y_test')
    plt.xlabel('pred_test')
    plt.ylabel('y_test')
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()), lw = 3, color ='red')
    st.pyplot(fig)
    
    
    return [residus, residus_norm, residus_std]
    
def graph_res_sfm(y_train, y_test, pred_train, pred_test):
    #Normalit√© des r√©sidus:
    ## Calcul des r√©sidus et r√©sidus normalis√©s:
    residus = pred_train - y_train 
    residus_norm = (residus-residus.mean())/residus.std()
    residus_std = residus/np.sqrt(np.sum(residus**2)/(len(residus)-1))
    
    # Graphes :
    fig = plt.figure(figsize = (15,10))
    # Espacement des graphes:
    plt.subplots_adjust(left=0.1,
                        bottom=0.1,
                        right=0.9,
                        top=0.9,
                        wspace=0.2,
                        hspace=0.4)
    
    plt.rcParams['axes.facecolor'] = 'whitesmoke'
    
    ## Graphe normalisation r√©sidus:
    plt.subplot(2,2,1)
    stats.probplot(residus_norm, plot = plt)
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    
    ## Graphe r√©sidus en fonction de pred_train (valeurs ajust√©es):
    plt.subplot(2,2,2)
    plt.scatter(pred_train, residus, alpha = 0.3)
    plt.plot((pred_train.min(), pred_train.max()), (0, 0), lw=3, color='red')
    plt.plot((pred_train.min(), pred_train.max()), (2*residus.std(), 2*residus.std()), 'r-', lw=1.5, label = '¬± 2 œÉ') 
    plt.plot((pred_train.min(), pred_train.max()), (3*residus.std(), 3*residus.std()), 'r--', lw=1.5, label = '¬± 3 œÉ')
    plt.plot((pred_train.min(), pred_train.max()), (-2*residus.std(), -2*residus.std()), 'r-',lw=1.5)
    plt.plot((pred_train.min(), pred_train.max()), (-3*residus.std(), -3*residus.std()), 'r--', lw=1.5)
    plt.title('R√©sidus en fonction de pred_train (valeurs ajust√©es)')
    plt.xlabel('pred_train (valeurs ajust√©es)')
    plt.ylabel('R√©sidus')
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.legend(loc = 'lower left')
    
    ## Graphe boxplot des r√©sidus:
    plt.subplot(2,2,3)
    sns.boxplot(residus, notch=True)
    plt.title('Boite √† moustache des r√©sidus')
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.xlabel('r√©sidus')
    
    ## Graphe pr√©dictions en fonction de y_test (= le long de la droite si elles sont bonnes):
    plt.subplot(2,2,4)
    plt.scatter(pred_test, y_test, alpha = 0.3)
    plt.title('Nuage de points entre pred_test et y_test')
    plt.xlabel('pred_test')
    plt.ylabel('y_test')
    plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
    plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()), lw = 3, color ='red')
    st.pyplot(fig)
    
    return [residus, residus_norm, residus_std]

# Cr√©ation d'un DataFrame regroupant les donn√©es d'origine de df enrichi des valeurs ajust√©es,
# des r√©sidus, des distances de cook
def df_res(sfm_train, y_train, pred_train, residus):
    #chargement data:
    #dfdata = pd.read_csv('data.csv', index_col = 0)
    
    #Analyse statsmodel:
    X = sfm_train
    X = sm.add_constant(X) #ajout d'une constante
    y = y_train
    model = sm.OLS(y, X)
    results = model.fit()
    
    # distance de Cook (= identification des points trop influents):
    influence = results.get_influence() # results DOIT √™tre un model de statsmodels
    (c, p) = influence.cooks_distance  # c = distance et p = p-value
    
    # AJOUT DES VARIABLES CALCULEES A DF (pred_train, r√©sidus, r√©sidus normalis√©s et distance de cook)
    
    #PRED_TRAIN:
    
    ## Cr√©ation d'un DataFrame stockant pred_train en conservant les index et arrondir √† une d√©cimale:
    y_pred = pd.DataFrame(pred_train, index = sfm_train.index)
    y_pred= pd.DataFrame(y_pred.rename(columns ={0:'pred_train'}))
    y_pred = round(y_pred.pred_train,1)
   
    ## Cr√©ation df1 (= Ajout de pred_train √† df):
    df1 = df.join(y_pred)
    
    ## Suppression des Nans:
    df1 = df1.dropna()
    
    #RESIDUS:
    
    ## Cr√©ation d'un DataFrame stockant les r√©sidus:
    res = pd.DataFrame(residus)
    res.rename(columns ={'CO2':'residus'}, inplace = True)
    
    ## Ajout des r√©sidus √† df1:
    df1 = df1.join(res)
    
    # RESIDUS NORMALISES:
    
    ## Cr√©ation d'un DataFrame stockant les r√©sidus noramlis√©s:
    res_norm = pd.DataFrame(residus_norm)
    res_norm.rename(columns ={'CO2':'residus_normalis√©s'}, inplace = True)
    
    ## Ajout des r√©sidus normalis√©s √† df1:
    df1 = df1.join(res_norm)
    
    ## Labelisation des r√©sidus normalis√©s √† 2 √©carts-types:
    liste = []
    for residus in df1.residus_normalis√©s:
        if residus >2 or residus <-2:
            liste.append('res norm ¬±2 œÉ')
        else:
            liste.append('ok')
    ## ajout liste (=r√©sidus normalis√©s lab√©lis√©s √† 2 EC) √† df1:
    df1['res_norm_¬±2_œÉ'] = liste
    
    ## Labelisation des r√©sidus normalis√©s √† 3 √©carts-types:
    liste = []
    for residus in df1.residus_normalis√©s:
        if residus >3 or residus <-3:
            liste.append('res norm ¬±3 œÉ')
        else:
            liste.append('ok')
    ## ajout liste (=r√©sidus normalis√©s lab√©lis√©s √† 3 EC) √† df1:
    df1['res_norm_¬±3_œÉ'] = liste
    
    # DISTANCE DE COOK:
    
    ## Cr√©ation d'un DataFrame stockant les distances de Cook:
    dist_cook = pd.DataFrame(c, index = res_norm.index)
    dist_cook.rename(columns ={0:'dist_cook'}, inplace = True)
    
    ## Ajout des distances de Cook √† df1:
    df1 = df1.join(dist_cook)
    
    ## Labelisation des distances de Cook:
    liste = []
    for dist in df1.dist_cook:
        if dist > 4/len(y_train) or dist > 1:
            liste.append('observation influente')
        else:
            liste.append('observation non influente')
    ## ajout liste (=r√©sidus normalis√©s lab√©lis√©s √† 3 EC) √† df1:
    df1['observation_influente'] = liste
    
    # Validation des r√©sidus √©lev√©s √† 2 et 3 √©carts-types:
    st.write('Pourcentage des r√©sidus √† ¬±2 ecarts-types (doit √™tre <0.05) =',round(df1[(df1['residus_normalis√©s']>2)|(df1['residus_normalis√©s']<-2)].residus_normalis√©s.count()/df1.residus_normalis√©s.count(), 3))
    st.write('Pourcentage des r√©sidus √† ¬±3 ecarts-types (doit √™tre <0.003) =',round(df1[(df1['residus_normalis√©s']>3)|(df1['residus_normalis√©s']<-3)].residus_normalis√©s.count()/df1.residus_normalis√©s.count(), 3))
    st.write('')

    
    # Affichage des valeurs les plus influentes du mod√®le:  
    fig = plt.figure(figsize = (15,5))
    ax = fig.add_subplot(111)
    ax.scatter(df1[df1['observation_influente'] == 'observation influente'].pred_train, df1[df1['observation_influente'] == 'observation influente'].residus, color = 'orange', label = 'observation influente')
    ax.scatter(df1[df1['observation_influente'] == 'observation non influente'].pred_train, df1[df1['observation_influente'] == 'observation non influente'].residus, alpha = 0.2, label = 'observation non influente')
    ax.plot((df1.pred_train.min(), df1.pred_train.max()), (0, 0), lw=3, color='red')
    ax.plot((df1.pred_train.min(), df1.pred_train.max()), (2*df1.residus.std(), 2*df1.residus.std()), 'r-', lw=1.5, label = '2 œÉ') 
    ax.plot((df1.pred_train.min(), df1.pred_train.max()), (3*df1.residus.std(), 3*df1.residus.std()), 'r--', lw=1.5, label = '3 œÉ')
    ax.plot((df1.pred_train.min(), df1.pred_train.max()), (-2*df1.residus.std(), -2*df1.residus.std()), 'r-',lw=1.5)
    ax.plot((df1.pred_train.min(), df1.pred_train.max()), (-3*df1.residus.std(), -3*df1.residus.std()), 'r--', lw=1.5)
    ax.set(title='R√©sidus en fonction de pred_train (valeurs ajust√©es)')
    ax.set(xlabel='pred_train (valeurs ajust√©es)')
    ax.set(ylabel='R√©sidus')
    ax.legend()
    st.pyplot(fig) 
    
    st.write('')
    st.write('')
    st.write('')
    st.markdown("###### Analyse des r√©sidus √†: üëá")
    choix_EC = st.radio("",
                           ["¬±2 √©carts-types",
                            "¬±3 √©carts-types",
                            "r√©sidus influant trop fortement sur le mod√®le (distance de Cook)"],
                           key="visibility")
    st.write('')
    st.write('')
    st.write('')

    # Repr√©sentation graphique des r√©sidus - de quoi sont compos√©s ces r√©sidus √©lev√©s? - qu'est-ce qui les caract√©risent?:
    
    if choix_EC != 'r√©sidus influant trop fortement sur le mod√®le (distance de Cook)':
        
        if choix_EC == '¬±2 √©carts-types':
            EC = 2
            res_boxplot = 'res_norm_¬±2_œÉ'
                
        if choix_EC == '¬±3 √©carts-types':
            EC = 3
            res_boxplot = 'res_norm_¬±3_œÉ'
        
        st.markdown('###### R√©partition des r√©sidus √©lev√©s selon les variables cat√©gorielles')
        
        # Repr√©sentation graphique des r√©sidus - de quoi sont compos√©s ces r√©sidus √©lev√©s?:
        fig = plt.figure(figsize = (16,8))
        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=0.9,
                            top=0.9,
                            wspace=0,
                            hspace=0.1)
        # Graphe Marque:
        plt.subplot(221)
        plt.pie(df1.Marque[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts(),
                        labels = df1.Marque[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts().index,
                       labeldistance=1.2,
                       pctdistance = 0.8,
                       autopct = lambda x: str(round(x,2))+'%',
                       shadow =True)
            
        # Graphe Carburant:
        plt.subplot(222)
        plt.pie(df1.Carrosserie[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts(),
                        labels = df1.Carrosserie[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts().index,
                        autopct = lambda x: str(round(x,2))+'%',
                        labeldistance=1.2,
                        pctdistance = 0.8,
                        shadow =True)
            
        # Graphe gamme:
        plt.subplot(223)
        plt.pie(df1.gamme2[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts(),
                labels = df1.gamme2[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts().index,
                autopct = lambda x: str(round(x,2))+'%',
                labeldistance=1.2,
                pctdistance = 0.8,
                shadow =True)
        
        
        # Graphe carburant:
        plt.subplot(224)
        plt.pie(df1.Carburant[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts(),
                labels = df1.Carburant[(df1['residus_normalis√©s']>EC)|(df1['residus_normalis√©s']<-EC)].value_counts().index,
                autopct = lambda x: str(round(x,2))+'%',
                pctdistance = 0.8,
                shadow =True)
        st.pyplot(fig)
        
        st.write('')
        st.write('')
        st.write('')
        
        st.markdown('###### Comparaison des puissance maximales et des masses en fonction de la valeur des r√©sidus')
        
        fig = plt.figure(figsize = (10,3.5))    
        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=1,
                            top=1,
                            wspace=0.4,
                            hspace=0)
        plt.subplot(121)
        sns.boxplot(data = df1, x = res_boxplot, y = 'puiss_max')
            
        plt.subplot(122)
        sns.boxplot(data = df1, x = res_boxplot, y = 'masse_ordma_min')
        st.pyplot(fig)
        
 
    
    if choix_EC == 'r√©sidus influant trop fortement sur le mod√®le (distance de Cook)':
        fig = plt.figure(figsize = (16,8))
        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=0.9,
                            top=0.9,
                            wspace=0,
                            hspace=0.1)
        # Graphe Marque:
        plt.subplot(221)
        plt.pie(df1.Marque[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts(),
                        labels = df1.Marque[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts().index,
                       labeldistance=1.2,
                       pctdistance = 0.8,
                       autopct = lambda x: str(round(x,2))+'%',
                       shadow =True)
            
        # Graphe Carburant:
        plt.subplot(222)
        plt.pie(df1.Carrosserie[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts(),
                        labels = df1.Carrosserie[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts().index,
                       labeldistance=1.2,
                       pctdistance = 0.8,
                       autopct = lambda x: str(round(x,2))+'%',
                       shadow =True)
            
        # Graphe gamme:
        plt.subplot(223)
        plt.pie(df1.gamme2[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts(),
                        labels = df1.gamme2[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts().index,
                       labeldistance=1.2,
                       pctdistance = 0.8,
                       autopct = lambda x: str(round(x,2))+'%',
                       shadow =True)
        
        
        # Graphe carburant:
        plt.subplot(224)
        plt.pie(df1.Carburant[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts(),
                        labels = df1.Carburant[(df1['observation_influente'] == 'observation influente')|(df1['observation_influente'] == 'observation influente')].value_counts().index,
                       labeldistance=1.2,
                       pctdistance = 0.8,
                       autopct = lambda x: str(round(x,2))+'%',
                       shadow =True)
        st.pyplot(fig)
        
        st.write('')
        st.write('')
        st.write('')
        
        st.markdown('###### Comparaison des puissance maximales et des masses en fonction de la valeur des r√©sidus')
        
        fig = plt.figure(figsize = (10,3.5))    
        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=1,
                            top=1,
                            wspace=0.4,
                            hspace=0)
        plt.subplot(121)
        sns.boxplot(data = df1, x = df1['observation_influente'], y = 'puiss_max')
            
        plt.subplot(122)
        sns.boxplot(data = df1, x = df1['observation_influente'], y = 'masse_ordma_min')
        st.pyplot(fig)
    
    

# ANIMATION STREAMLIT------------------------------------------------------------------------------------------------------------------------------
if page == pages[3]:
    st.write('#### Mod√©lisation: R√©gression multiple')
    
    tab1, tab2 = st.tabs(['Analyse de la variable cible CO‚ÇÇ', 'R√©gressions multiples'])
    
    with tab1:
        c1, c2 = st.columns((1,1))
        with c1:
            st.markdown("###### Choississez le type d'analyse de la variable cible CO‚ÇÇ üëá")
            Analyse_Y = st.radio(" ",
                                 ["Analyse globale", "Analyse par type de carburant"],
                               key="visibility",
                               horizontal = True)
            st.write('')
            from scipy.stats import norm
            # Analyse de la distribution target (CO2 (g/km)):
            dist = pd.DataFrame(target_reg)
            
            if Analyse_Y == "Analyse globale":
                fig = plt.figure(figsize =(8,5))
                
                # Espacement des graphes:
                plt.subplots_adjust(left=0.1,
                                    bottom=0.1,
                                    right=0.9,
                                    top=0.9,
                                    wspace=0.2,
                                    hspace=1) 
                plt.subplot(211)
                
                # Histogramme de distribution:
                plt.hist(dist, bins=60, density=True, rwidth = 0.8, color='steelblue')
                plt.title('Histogramme de CO2 (g/km)')
                plt.xlim(0,400)
                plt.xlabel('CO2 (g/km)')
                plt.yticks([])
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                
                # Repr√©sentation de la loi normale avec la moyenne et l'√©cart-type de la distribution -
                # Affichage de la moyenne et la m√©diane de la distribution:
                
                x_axis = np.arange(0,400,1)
                plt.plot(x_axis, norm.pdf(x_axis, dist.mean(), dist.std()),'r', linewidth = 3)
                plt.xlim(0,400)
                plt.plot((dist.mean(), dist.mean()), (0, 0.015), 'r-', lw=1.5, label = 'moyenne de la distribution')
                plt.plot((dist.median(), dist.median()), (0, 0.015), 'r--', lw=1.5, label = 'm√©diane de la distribution')
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                plt.legend()
                
                # Boite √† moustache de la distribution:
                plt.subplot(212)
                sns.boxplot(x=dist.CO2, notch=True)
                plt.title('Boite √† moustache de CO2 (g/km)')
                plt.xlabel('CO2 (g/km)')
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                plt.xlim(0,400)
                
                st.pyplot(fig)
                
            if Analyse_Y == "Analyse par type de carburant":
                fig = plt.figure(figsize =(10,12))
                
                # Espacement des graphes:
                plt.subplots_adjust(left=0.1,
                                    bottom=0.1,
                                    right=0.9,
                                    top=0.9,
                                    wspace=0.2,
                                    hspace=0.6)
                # Histogrammes de distribution des v√©hicules essence et des v√©hicules diesel :
                plt.subplot(311)
                ES = df.CO2[df['Carburant']=='ES']
                GO = df.CO2[df['Carburant']=='GO']
                
                plt.hist(ES,
                         bins=80,
                         density=True,
                         alpha=0.4,
                         color='green',
                         label ='Distribution des v√©hicules essence')
                
                plt.hist(GO,
                         bins=40,
                         density=True,
                         alpha=0.4,
                         color='orange',
                         label ='Distribution des v√©hicules diesel')
                
                plt.title('Histogramme de CO2 (g/km) en fonction du carburant')
                plt.xlabel('CO2 (g/km)')
                plt.yticks([])
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                plt.legend()
                
                # R√©pr√©sentation des distributions des v√©hicules essence et diesel en prenant en compte uniquement
                # leurs moyennes et leurs √©carts-types (= aspect d'une loi normale avec ces moyennes et ces √©carts-types):
                ## Repr√©sentation de la loi normale avec la moyenne et l'√©cart-type de la distribution des v√©hicules essence ES:
                
                plt.subplot(312)
                x_axis = np.arange(0,400,1)
                plt.plot(x_axis,
                         norm.pdf(x_axis, ES.mean(), ES.std()),
                         'g',
                         linewidth = 3,
                         alpha = 0.8,
                         label ='loi normale [ES)]')
                plt.xlim(0,400)
                plt.plot((ES.mean(), ES.mean()), (0, 0.015), 'g', lw=1.5, label = 'moyenne de la distribution ES')
                plt.plot((ES.median(), ES.median()), (0, 0.015), 'g--', lw=1.5, label = 'm√©diane de la distribution ES')
                
                ## Repr√©sentation de la loi normale avec la moyenne et l'√©cart-type de la distribution des v√©hicules diesel GO:
                plt.plot(x_axis,
                         norm.pdf(x_axis, GO.mean(), GO.std()),
                         'orange',
                         linewidth = 3,
                         alpha = 0.8,
                         label ='loi normale [GO]')
                plt.xlim(0,400)
                plt.plot((GO.mean(), GO.mean()), (0, 0.015), 'y', lw=1.5, label = 'moyenne de la distribution GO')
                plt.plot((GO.median(), GO.median()), (0, 0.015), 'y--', lw=1.5, label = 'm√©diane de la distribution GO')
                plt.title('Repr√©sentation des lois normales des distributions des v√©hicules essence et diesel suivant leurs moyennes et √©carts-types')
                plt.xlabel('CO2 (g/km)')
                plt.yticks([])
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                plt.legend()
                
                # Boite √† moustache de la distribution en fonction du carburant:
                plt.subplot(313)
                sns.boxplot(data = df, y = 'Carburant' , x = 'CO2', palette = ['green','gold'], notch=True)
                plt.xticks(rotation = 'vertical')
                plt.title('Boite √† moustache de CO2 (g/km) en fonction du type de carburant')
                plt.xlabel('CO2 (g/km)')
                plt.xlim(0,400)
                plt.grid(linestyle = ':', c = 'g', alpha = 0.3)
                
                st.pyplot(fig)

     
    with tab2:
        st.markdown("**M√©thodologie**:  \n1. s√©lection du dataset,  \n2. construction d'un premier mod√®le g√©n√©ral √† partir de l'ensemble des variables du dataset,  \n3. construction d'un second mod√®le affin√© apr√®s s√©lection des variables les plus influentes,  \n3. pour chaque mod√®le: analyse des metrics et r√©sidus et s√©lection des donn√©es les plus pertinentes, puis retour √† l'√©tape 1")
        st.write('___')
        c1, c2, c3= st.columns((0.4, 0.4, 1))
        with c1:
            st.markdown("###### Dataset √† analyser: üëá")
            choix_dataset = st.radio("",
                                     ["Dataset complet (v√©hicules essence et diesel)",
                                      "V√©hicules diesel uniquement",
                                      "V√©hicules essence uniquement"])
        
        with c2:
            st.markdown("###### Mod√®le de r√©gression √† analyser: üëá")
            choix_model = st.radio("",
                                   ["Mod√®le g√©n√©ral",
                                    "Mod√®le affin√©"])
        with c3:
             st.markdown("###### Analyse: üëá")
             choix_param = st.radio("",
                                    ["Metrics & Coefficients des variables",
                                     "R√©sidus"])


                              
        if choix_dataset == 'Dataset complet (v√©hicules essence et diesel)':
            dataset = data
            cible = target_reg
            model = 'lr.joblib'
           
        if choix_dataset == 'V√©hicules diesel uniquement':
            dataset = data_go
            cible = target_go
            model = 'lr_go.joblib'
            
        if choix_dataset == 'V√©hicules essence uniquement':
            dataset = data_es
            cible = target_es
            model = 'lr_es.joblib'
        
        if choix_model == "Mod√®le g√©n√©ral":
            #Standardisation, split du dataset, r√©gression:
                X_train, X_test, y_train, y_test = standardisation_lr(dataset, cible)
                lr, pred_train, pred_test = regression_lineaire(model, X_train, y_train, X_test, y_test)
        
        if choix_model == "Mod√®le affin√©":
            #Standardisation, split du dataset, r√©gression:
                X_train, X_test, y_train, y_test = standardisation_lr(dataset, cible)
                lr_sfm, pred_train, pred_test, sfm_train, sfm_test = selecteur(X_train, y_train, X_test, y_test)
        
        if choix_param == "Metrics & Coefficients des variables":
            c1, c2, c3, c4 = st.columns((1, 1.2, 0.2, 1.1))
            if choix_model == "Mod√®le g√©n√©ral":
                with c1:
                    st.write("##### **Metrics:**")
                    st.write('')
                    metrics_lr(lr, X_train, y_train, X_test, y_test, pred_train, pred_test)
            
                with c2:
                    st.write("##### **Coefficients des variables:**")
                    coef_lr(lr, X_train)
            
            if choix_model == "Mod√®le affin√©":
                with c1:
                    st.write("##### **Metrics:**")
                    st.write('')
                    metrics_sfm(lr_sfm, X_train, y_train, X_test, y_test, pred_train, pred_test, sfm_train, sfm_test)
                    
                with c2:
                    st.write("##### **Coefficients des variables retenues par le mod√®le:**")
                    coef_sfm(lr_sfm, sfm_train)
                
                with c4:
                    
                    if choix_dataset == 'Dataset complet (v√©hicules essence et diesel)':
                        st.markdown("##### Repr√©sentation graphique de la cible CO‚ÇÇ par type de carburant en fonction de la masse et de la puissance des v√©hicules:")
                        import streamlit as st
                        from PIL import Image
                            
                        graph4D = st.radio("",
                                           ["Vid√©o", "Vue 1", "Vue 2", "Vue 3", "Vue 4"],
                                           key="visibility",
                                           horizontal = True)
                        if graph4D == 'Vid√©o':
                            st.video('Graphe_4D.mp4', format="video/mp4", start_time=0)
                        if graph4D == 'Vue 1':
                            image = Image.open('4D1.png')
                            st.image(image)
                        if graph4D == 'Vue 2':
                            image = Image.open('4D2.png')
                            st.image(image)
                        if graph4D == 'Vue 3':
                            image = Image.open('4D3.png')
                            st.image(image)
                        if graph4D == 'Vue 4':
                            image = Image.open('4D4.png')
                            st.image(image)
                                            
        if choix_param == "R√©sidus":
            c1, c2 = st.columns((1.3, 1))                
            if choix_model == "Mod√®le g√©n√©ral":
                with c1:
                    st.write("##### **Analyse graphique des r√©sidus:**")
                    residus, residus_norm, residus_std = graph_res(y_train, y_test,
                                                                   pred_train,
                                                                   pred_test)
                    st.write('')
                    st.write('')
                    st.write('')
                    
                    st.write("##### **Analyse graphique sp√©cifique des r√©sidus √©lev√©s et fortement influents:**")               
                    df_res(X_train, y_train, pred_train, residus)
                    
            if choix_model == "Mod√®le affin√©":
                with c1:
                    st.write("##### **Analyse graphique des r√©sidus:**")
                    residus, residus_norm, residus_std = graph_res_sfm(y_train, y_test,
                                                                       pred_train,
                                                                       pred_test)
                    st.write('')
                    st.write('')
                    st.write('')
                    
                    st.write("##### **Analyse graphique sp√©cifique des r√©sidus √©lev√©s et fortement influents:**")               
                    df_res(sfm_train, y_train, pred_train, residus)
    
        

#_______________________________________________________________________________________________________
#
#                                   Page 4 : classification 
#_______________________________________________________________________________________________________

# CHARGEMENT DES JEUX DE DONNEES NETTOYES ET DES TARGETS CORRESPONDANTES: ------------------------------
df = pd.read_csv('df.csv', index_col = 0)

## Matrice de confusion de chaque mod√®le:
matrix_rf = load('matrice_rf.joblib')
matrix_rf_opt = load('matrice_rf_opt.joblib')
matrix_knn = load('matrice_knn.joblib')
matrix_knn_opt = load('matrice_knn_opt.joblib')
matrix_svm = load('matrice_svm.joblib')
matrix_svm_opt = load('matrice_svm_opt.joblib')

## Rapport de classification de chaque mod√®le:
rap_rf = load('rapport_class_rf.joblib')
rap_rf_opt = load('rapport_class_rf_opt.joblib')
rap_knn = load('rapport_class_knn.joblib')
rap_knn_opt = load('rapport_class_knn_opt.joblib')
rap_svm = load('rapport_class_svm.joblib')
rap_svm_opt = load('rapport_class_svm_opt.joblib')
   
# On s√©pare les variables num√©riques et cat√©gorielles
var_num = df.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
var_cat = df.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles

# On r√©cup√®re la variable cible
target_class = df['Cat_CO2'].squeeze()     # Variable cible pour la classification

var_num = var_num.drop(['CO2'], axis = 1)  # Les variables cibles sont √©limin√©es des variables num√©riques
var_cat = var_cat.drop(['Cat_CO2'], axis = 1)

# Les variables cat√©gorielles sont transform√©es en indicatrices
var_cat_ind = pd.get_dummies(var_cat)

# On r√©cup√®re les variables explicatives
data = var_num.join(var_cat_ind)

# FONCTIONS: ----------------------------------------------------------------------------

# Fonction pour afficher les 3 matrices de confusion des 3 mod√®les optimis√©s:
def matrice(matrice, titre):
    classes = ['A','B','C','D','E','F','G']
    plt.imshow(matrice, interpolation='nearest',cmap='Blues')
    plt.title(titre)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)
    plt.grid(False)
    
    for i, j in itertools.product(range(matrice.shape[0]), range(matrice.shape[1])):
        plt.text(j, i, matrice[i, j],
                 horizontalalignment="center",
                 color="white" if (matrice[i, j] > ( matrice.max() / 2) or matrice[i, j] == 0) else "black")
    plt.ylabel('Cat√©gories r√©elles')
    plt.xlabel('Cat√©gories pr√©dites')
    st.pyplot()

if page == pages[4]:
    st.write('#### Mod√©lisation: Classification multi-classes')
        
    st.markdown("Explication de la d√©marche:  \n - un **premier mod√®le** est g√©n√©r√© √† partir de l'ensemble des hyperparam√®tres,  \n - un **second mod√®le optimis√©** est g√©n√©r√© apr√®s s√©lection des meilleurs hyperparam√®tres.")
    st.markdown('Nous proc√©dons √† une classification multiple. Nous avons donc choisi les classifieurs adapt√©s.')
    st.markdown('Nous en avons s√©lectionn√© 3 pour cette √©tude: SVM, KNN et Random Forest')
    tab1, tab2, tab3 = st.tabs(['Donn√©es', 'Classifications multiples', 'Comparaison des mod√®les'])
    
    
    # S√©paration en donn√©es d'entra√Ænement et de test
    X_train, X_test, y_train, y_test = train_test_split(data, target_class,
                                                    test_size = 0.25,
                                                    random_state = 2,
                                                    stratify = target_class)

    # Les variables num√©riques doivent √™tre standardis√©es
    cols = ['puiss_max', 'masse_ordma_min']
    sc = StandardScaler()
    X_train[cols] = sc.fit_transform(X_train[cols])
    X_test[cols] = sc.transform(X_test[cols])
    
    with tab1:
        st.write('#### Revue des donn√©es √† classifier')
        st.markdown('Le DataFrame utilis√© pour la classification multiple comporte : \n')
        c1, c2, c3 = st.columns((1.5, 1, 0.5))
        
        with c1:
            st.markdown('Les variables cat√©gorielles :\n')
            st.write(var_cat.head())     

        
        with c2:
            st.markdown('Les variables num√©riques :\n')
            st.write(var_num.head())
        
        with c3:
            st.markdown('La variable cible :\n')
            st.write(target_class.head())
            
        c1, c2 = st.columns((1.5,1))
        
        with c1:
            sns.countplot(data = df, x = 'Cat_CO2', order = ('A','B','C','D','E','F','G'))
            plt.title('R√©partition de la variable cible Cat_CO2')
            st.pyplot()
            
    with tab2:
        st.markdown("##### Quel mod√®le voulez-vous analyser? üëá")
        choix_model = st.radio(" ",
                             ["SVM",
                              "KNN",
                              "Random Forest"],
                           key="visibility",
                           horizontal = True)
        
        c1, c2 = st.columns((1.5, 1.5))
        
        
        if choix_model == 'SVM':
             rapport = rap_svm
             rapport_optim = rap_svm_opt
             matrix = matrix_svm
             matrix_optim = matrix_svm_opt
           
        if choix_model == 'KNN':
            rapport = rap_knn
            rapport_optim = rap_knn_opt
            matrix = matrix_knn
            matrix_optim = matrix_knn_opt
            
        if choix_model == 'Random Forest':            
            rapport = rap_rf
            rapport_optim = rap_rf_opt
            matrix = matrix_rf
            matrix_optim = matrix_rf_opt        
        
        fig = plt.figure(figsize = (10,10))        

        # Espacement des graphes:
        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=0.9,
                            top=0.9,
                            wspace=0.5,
                            hspace=0.4)
        
        with c1:
            plt.subplot(121)
            matrice(matrix, 'Matrice de confusion du mod√®le '+choix_model+' standard')
            st.write('Le rapport de classification '+choix_model+' standard')
            st.text(rapport) 
            
        
        with c2:
            plt.subplot(122)
            matrice(matrix_optim, 'Matrice de confusion du mod√®le '+choix_model+' optimis√©')
            st.write('Le rapport de classification '+choix_model+' optimis√©')
            st.text(rapport_optim)                 
        
        
    with tab3:
        
        # Affichage et comparaison des 3 matrices de confusion des 3 mod√®les optimis√©s
        st.write("Comparaison des matrices de confusion des 3 mod√®les optimis√©s \n")

        c1, c2, c3 = st.columns((1, 1.05, 1))
        with c1:
            # Matrice de confusion du mod√®le SVM optimis√©:
                plt.subplot(131)
                matrice(matrix_svm_opt, 'Matrice de confusion du mod√®le SVM optimis√©')
                st.text(rap_svm_opt)

        with c2:
            # Matrice de confusion du mod√®le KNN optimis√©:
                plt.subplot(132)
                matrice(matrix_knn_opt, 'Matrice de confusion du mod√®le KNN optimis√©')
                st.text(rap_knn_opt)

        with c3:
            # Matrice de confusion du mod√®le RF optimis√©:
                plt.subplot(133)
                matrice(matrix_rf_opt, 'Matrice de confusion du mod√®le RF optimis√©')
                st.text(rap_rf_opt)

#_______________________________________________________________________________________________________
#
#                                   Page 5 : Interpr√©tation SHAP multi-classes 
#_______________________________________________________________________________________________________

#CHARGEMENT DES LIBRAIRIES: ----------------------------------------------------------------------------

import shap
from sklearn.tree import plot_tree

# CHARGEMENT DES MODELES: ------------------------------------------------------------------------

## Mod√®les:
model_rf_opt = load('clf_rf_grid.joblib')
model_knn_opt = load('clf_knn_grid.joblib')
model_svm_opt = load('clf_svc_grid.joblib')


## Explainers:
explainer_rf_opt = load('explainer_rf_opt.expected_value.joblib')
explainer_knn_opt = load('explainer_knn.expected_value.joblib')
explainer_svm_opt = load('explainer_svm_opt.expected_value.joblib')

## SHAP_VALUES:
shap_values_rf_opt = load('shap_values_rf_opt.joblib')
shap_values_knn_opt = load('shap_values_knn_opt.joblib')
shap_values_svm_opt = load('shap_values_svm_opt.joblib')



## Dataframes et Targets:
df_class = pd.read_csv('df.csv', index_col = 0)
df_class = df_class.drop('Cat_CO2', axis = 1)
df_class = df_class.drop('CO2', axis = 1)

X_test_75 = pd.read_csv('X_test_75.csv', index_col = 0)

target_class = pd.read_csv('target_class.csv', index_col = 0)
target_class = target_class.squeeze()

# Preprocessing dataset:-----------------------------------------------------------------------------
  
# On s√©pare les variables num√©riques et cat√©gorielles
var_num = df_class.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
var_cat = df_class.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles

# Les variables cat√©gorielles sont transform√©es en indicatrices
var_cat_ind = pd.get_dummies(var_cat, drop_first = True)

# On r√©cup√®re les variables explicatives
feats = var_num.join(var_cat_ind)


# Pour rappel, le dataset feats regroupe les variables num√©riques et cat√©gorielles
# On r√©partit √©quitablement les classes entre les jeux d'entrainement et de test.
X_train, X_test, y_train, y_test = train_test_split(feats, target_class,
                                                    test_size = 0.25,
                                                    random_state = 2,
                                                    stratify = target_class)

# Les variables num√©riques doivent √™tre standardis√©es
cols = ['puiss_max', 'masse_ordma_min']
sc = StandardScaler()
X_train[cols] = sc.fit_transform(X_train[cols])
X_test[cols] = sc.transform(X_test[cols])

# ANIMATION STREAMLIT------------------------------------------------------------------------------------------------------------------------------
if page == pages[5]:
    st.write('#### Interpr√©tation SHAP multi-classes')
    st.markdown("###### Mod√®le de classification √† interpr√©ter: üëá")
    choix_model_shap = st.radio("",
                             ["Random Forest optimis√©",
                              "SVM optimis√©",
                              "KNN optimis√©"],
                             horizontal=False)
    
    if choix_model_shap == "Random Forest optimis√©":
        model = model_rf_opt
        shap_values = shap_values_rf_opt
        matrix = matrix_rf_opt
        titre_matrix = "Matrice de confusion - Random Forest optimis√©"
        explainer = explainer_rf_opt
        df1_titre = ''
        df1=''
        choix_cat = "**Random Forest optimis√©**: choisir les cat√©gories d'apr√®s la marice de confusion"
        choix_cat1 = "N'importe quel v√©hicule de X_test, composant la matrice de confusion, peut √™tre analys√©."
        
    if choix_model_shap == "SVM optimis√©":
        model = model_svm_opt
        shap_values = shap_values_svm_opt
        matrix = matrix_svm_opt
        titre_matrix = "Matrice de confusion - SVM optimis√©"
        explainer = explainer_svm_opt
        X_test = X_test_75
        y_test = y_test.loc[X_test.index]
        df1 = df.join(pd.DataFrame(model.predict(X_test), index = y_test.index))
        df1 = df1.join(df_2013['D√©signation commerciale'])
        df1 = df1.rename({0:'Cat_CO2_pred'}, axis = 1)
        df1 = df1.join(pd.DataFrame(pd.DataFrame(model.predict(X_test)).index, index = y_test.index))
        df1 = df1.rename({0:'index_shape'}, axis = 1)
        df1 = df1.dropna(subset=['Cat_CO2_pred'])
        df1 = df1.rename({'CO2':'CO‚ÇÇ (g/km)'}, axis = 1)
        df1 = df1[df1.columns[[8,9,3,0,10,1,2,4,5,6,7,11]]]
        df1_titre = "Tableau regroupant les v√©hicules pouvant √™tre analys√©s pour le mod√®les SVM optimis√©"
        choix_cat = "**SVM optimis√©**: choisir le couple cat√©gorie r√©elle / cat√©gorie pr√©dite d'apr√®s le tableau ci-dessus ‚òùÔ∏è"
        choix_cat1 = "Afin de diminuer les temps de calcul, seuls 75 v√©hicules, pris au hasard dans X_test, peuvent √™tre analys√©s."
        
    if choix_model_shap == "KNN optimis√©":
        model = model_knn_opt
        shap_values = shap_values_knn_opt
        matrix = matrix_knn_opt
        titre_matrix = "Matrice de confusion - KNN optimis√©"
        explainer = explainer_knn_opt
        X_test = X_test_75
        y_test = y_test.loc[X_test.index]
        df1 = df.join(pd.DataFrame(model.predict(X_test), index = y_test.index))
        df1 = df1.join(df_2013['D√©signation commerciale'])
        df1 = df1.rename({0:'Cat_CO2_pred'}, axis = 1)
        df1 = df1.join(pd.DataFrame(pd.DataFrame(model.predict(X_test)).index, index = y_test.index))
        df1 = df1.rename({0:'index_shape'}, axis = 1)
        df1 = df1.dropna(subset=['Cat_CO2_pred'])
        df1 = df1.rename({'CO2':'CO‚ÇÇ (g/km)'}, axis = 1)
        df1 = df1[df1.columns[[8,9,3,0,10,1,2,4,5,6,7,11]]]
        df1_titre = "Tableau regroupant les v√©hicules pouvant √™tre analys√©s pour le mod√®le KNN optimis√©"
        choix_cat = "**KNN optimis√©**: choisir le couple cat√©gorie r√©elle / cat√©gorie pr√©dite d'apr√®s le tableau ci-dessus ‚òùÔ∏è"       
        choix_cat1 = "Afin de diminuer les temps de calcul, seuls 75 v√©hicules, pris au hasard dans X_test, peuvent √™tre analys√©s."
        
    st.write('')
    st.write('')

    tab1, tab2 = st.tabs(['Interpr√©tabilit√© globale', 'Interpr√©tabilit√© locale'])
    
    with tab1:
        st.write("L'interpr√©tabilit√© globale permet d'expliquer le fonctionnement du mod√®le de point de vue g√©n√©ral √† travers 2 graphiques:")
        
        choix_plot = st.radio("",
                              ["summary plot",
                               "dependance plot"],
                              horizontal=False)
        st.write('___')
       
        c1, c2 = st.columns((0.7, 2))
        
        with c1:
            if choix_plot == "summary plot":
                st.write("Observez, √† l'aide de ces graphiques:   \n- les variables les plus importantes (ordre d√©croissant d'importance) et l'amplitude de leur impact sur du mod√®le ,   \n- l'importance des variables pour chaque cat√©gorie.")
                st.write('')
                st.markdown("###### Summary plot √† afficher: üëá")
                choix_model_shap = st.radio("",
                                            ["summary plot global",
                                             "summary plot par cat√©gorie"],
                                            horizontal=True)
                
                if choix_model_shap == "summary plot global":
                    st.write('')
                    st.write('')
                    st.write('')
                    
                    
                if choix_model_shap == "summary plot par cat√©gorie":
                    st.write('')
                    st.write('')
                    st.markdown("###### Cat√©gorie √† analyser: üëá")
                    choix_categorie = st.radio("",
                                               ["Cat√©gorie A",
                                                "Cat√©gorie B",
                                                "Cat√©gorie C",
                                                "Cat√©gorie D",
                                                "Cat√©gorie E",
                                                "Cat√©gorie F",
                                                "Cat√©gorie G"],
                                               key = "Summary",
                                               horizontal=True)
                    
            if choix_plot == "dependance plot":
                st.write("Description de ces graphiques:   \n- l'axe des abscisses x repr√©sente la valeur d'une variable 1,   \n- l'axe des odronn√©es y repr√©sente les valeurs de Shapley de cette m√™me variable 1 (une valeur de Shapley √©lev√©e tend √† l'appartenance de l'observation √† cette classe),   \n- les couleurs repr√©sentent la valeur d'une variable 2.")
                st.write('')
                st.write("Observez, √† l'aide de ces graphiques, les valeurs des variables 1 et 2:   \n- pour une valeur de Shapley √©lev√©e (= appartenance √† cette classe),   \n- pour une valeur de Shapley faible (= non-appartenance √† cette classe.)")
                st.write('')
                
                            
                st.write('')
                st.markdown("###### Dependance plot √† afficher: üëá")
                choix_dependance_shap = st.radio("",
                                         ["Puissance max vs Masse",
                                          "Puissance max vs Carburant",
                                        "Masse vs Carburant",
                                            "Masse vs Puissance max"],
                                         horizontal=False)  
                st.write('')
                st.write('')
                
                st.markdown("###### Cat√©gorie √† analyser: üëá")
                choix_categorie = st.radio("",
                                           ["Cat√©gorie A",
                                            "Cat√©gorie B",
                                            "Cat√©gorie C",
                                            "Cat√©gorie D",
                                            "Cat√©gorie E",
                                            "Cat√©gorie F",
                                            "Cat√©gorie G"],
                                           key = "Dependance",
                                           horizontal=True)
                
        with c2: 
            if choix_plot == "summary plot":
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                if choix_model_shap == "summary plot global":
                    # Summary_plot:
                        st_shap(shap.summary_plot(shap_values,
                                                  X_test,
                                                  plot_type="bar",
                                                  class_names = ['A', 'B', 'C', 'D', 'E', 'F','G']))
                                    
                if choix_model_shap == "summary plot par cat√©gorie":                
                    if choix_categorie == "Cat√©gorie A":
                        st_shap(shap.summary_plot(shap_values[0],
                                                  X_test,
                                                  feature_names=feats.columns))
                                        
                    if choix_categorie == "Cat√©gorie B":
                        st_shap(shap.summary_plot(shap_values[1],
                                                  X_test,
                                                  feature_names=feats.columns))
                                            
                    if choix_categorie == "Cat√©gorie C":
                        st_shap(shap.summary_plot(shap_values[2],
                                                  X_test,
                                                  feature_names=feats.columns))
                                        
                    if choix_categorie == "Cat√©gorie D":
                        st_shap(shap.summary_plot(shap_values[3],
                                                  X_test,
                                                  feature_names=feats.columns))
                                        
                    if choix_categorie == "Cat√©gorie E":
                        st_shap(shap.summary_plot(shap_values[4],
                                                  X_test,
                                                  feature_names=feats.columns))
                                        
                    if choix_categorie == "Cat√©gorie F":
                        st_shap(shap.summary_plot(shap_values[5],
                                                  X_test,
                                                  feature_names=feats.columns))
                                        
                    if choix_categorie == "Cat√©gorie G":
                        st_shap(shap.summary_plot(shap_values[6],
                                                  X_test,
                                                  feature_names=feats.columns))
                        
            if choix_plot == "dependance plot":        
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                st.write('')
                
                if choix_dependance_shap == "Puissance max vs Masse":
                    if choix_categorie == "Cat√©gorie A":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[0], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))                       
                                                    
                    if choix_categorie == "Cat√©gorie B":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[1], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))   
                        
                    if choix_categorie == "Cat√©gorie C":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[2], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))       
                        
                    if choix_categorie == "Cat√©gorie D":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[3], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min")) 
                        
                    if choix_categorie == "Cat√©gorie E":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[4], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))
                        
                    if choix_categorie == "Cat√©gorie F":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[5], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))
                        
                    if choix_categorie == "Cat√©gorie G":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[6], 
                                                     X_test, 
                                                     interaction_index= "masse_ordma_min"))
                
                
                if choix_dependance_shap == "Puissance max vs Carburant":
                    if choix_categorie == "Cat√©gorie A":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[0], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))                       
                                                    
                    if choix_categorie == "Cat√©gorie B":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[1], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))   
                        
                    if choix_categorie == "Cat√©gorie C":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[2], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))       
                        
                    if choix_categorie == "Cat√©gorie D":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[3], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))   
                        
                    if choix_categorie == "Cat√©gorie E":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[4], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))
                                        
                    if choix_categorie == "Cat√©gorie F":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[5], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO")) 
                        
                    if choix_categorie == "Cat√©gorie G":
                        st_shap(shap.dependence_plot("puiss_max", 
                                                     shap_values[6], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))
                        
                if choix_dependance_shap == "Masse vs Carburant":
                    if choix_categorie == "Cat√©gorie A":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[0], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))                       
                                                    
                    if choix_categorie == "Cat√©gorie B":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[1], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))   
                        
                    if choix_categorie == "Cat√©gorie C":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[2], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))       
                        
                    if choix_categorie == "Cat√©gorie D":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[3], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))   
                        
                    if choix_categorie == "Cat√©gorie E":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[4], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO"))
                                        
                    if choix_categorie == "Cat√©gorie F":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[5], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO")) 
                        
                    if choix_categorie == "Cat√©gorie G":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[6], 
                                                     X_test, 
                                                     interaction_index= "Carburant_GO")) 
                        
                if choix_dependance_shap == "Masse vs Puissance max":
                    if choix_categorie == "Cat√©gorie A":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[0], 
                                                     X_test, 
                                                     interaction_index= "puiss_max"))
                    if choix_categorie == "Cat√©gorie B":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[1], 
                                                     X_test, 
                                                     interaction_index= "puiss_max")) 
                    if choix_categorie == "Cat√©gorie C":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[2], 
                                                     X_test, 
                                                     interaction_index= "puiss_max")) 
                    if choix_categorie == "Cat√©gorie D":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[3], 
                                                     X_test, 
                                                     interaction_index= "puiss_max")) 
                    if choix_categorie == "Cat√©gorie E":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[4], 
                                                     X_test, 
                                                     interaction_index= "puiss_max")) 
                    if choix_categorie == "Cat√©gorie F":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[5], 
                                                     X_test, 
                                                     interaction_index= "puiss_max")) 
                    if choix_categorie == "Cat√©gorie G":
                        st_shap(shap.dependence_plot("masse_ordma_min", 
                                                     shap_values[6], 
                                                     X_test, 
                                                     interaction_index= "puiss_max"))
               
    with tab2:
        c1, c2  = st.columns((1, 0.1))
        with c1:
            st.write("L'interpr√©tabilit√© locale permet d'expliquer le fonctionnement du mod√®le pour une instance.")
            st.write('')
        
        c1, c2, c3  = st.columns((0.4, 0.1, 1.6))
        
        with c1:
            plt.subplot(111)
            matrice(matrix, titre_matrix)
                        
            
        with c3:
            st.write(df1_titre)
            st.write(df1)
        
        c1, c2  = st.columns((1, 0.1))
        with c1:
            st.write('___')
        
        c1, c2  = st.columns((1, 0.1))
        with c1:
            
            st.write("###### Choisir les cat√©gories r√©elle et pr√©dite:  \n-", choix_cat, "  \n-", choix_cat1)
            st.write('')
            st.write('')
            
        c1, c2, c3 = st.columns((0.25, 0.25, 1))
        with c1:
            st.markdown("###### Cat√©gorie r√©elle: üëá")
            choix_cat_reel = st.radio("",
                                      ["A",
                                       "B",
                                       "C",
                                       "D",
                                       "E",
                                       "F",
                                       "G"],
                                      horizontal=False)
        
        with c2:    
            st.markdown("###### Cat√©gorie pr√©dite: üëá")
            choix_cat_pred = st.radio(" ",
                                      ["A",
                                       "B",
                                       "C",
                                       "D",
                                       "E",
                                       "F",
                                       "G"],
                                      horizontal=False)
        c1, c2  = st.columns((1, 1))
        with c1:
            st.write('')
            st.write('')
            # Cr√©ation d'un DataFrame regroupant par index (v√©hicules) les cat√©gories r√©elles de pollution, les cat√©gories pr√©dites
            # le mod√®le et l'index de y_pred
            
            df2 = df.join(pd.DataFrame(model.predict(X_test), index = y_test.index))
            df2 = df2.join(df_2013['D√©signation commerciale'])
            df2 = df2.rename({0:'Cat_CO2_pred'}, axis = 1)
            df2 = df2[(df2['Cat_CO2'] == choix_cat_reel)&(df2['Cat_CO2_pred'] == choix_cat_pred)]
            df2 = df2.join(pd.DataFrame(pd.DataFrame(model.predict(X_test)).index, index = y_test.index))
            df2 = df2.rename({0:'index_shape'}, axis = 1)
            df2 = df2.rename({'CO2':'CO‚ÇÇ (g/km)'}, axis = 1)
            df2 = df2.dropna(subset=['Cat_CO2_pred'])
            df2 = df2[df2.columns[[8,9,3,0,10,1,2,4,5,6,7,11]]]
                        
              
            
            st.dataframe(df2)
                
            st.write('')
            st.markdown("###### D'apr√®s le tableau ci-dessus ‚òùÔ∏è, choisir l'index du v√©hicule √† analyser: üëá")
            index = st.selectbox("",
                                 df2.index)
                                    
            if index == None:
                st.markdown("###### Aucun v√©hicule ne correspond √† votre choix - Tous les v√©hicules n'ont pas pu √™tre analys√©s avec ce mod√®le de classification  \n###### Veuillez vous r√©f√©rer au premier tableau, √† droite de la matrice de confusion, pour choisir les bonnes cat√©gories")
            
            else:
                st.write('')
                st.write('')
                st.write("###### Vous avez choisi d'analyser ce v√©hicule:")
                st.dataframe(df2[df2.index == index])
                st.write('')
                st.write('')
                st.write("Observez, √† l'aide de ces graphiques:   \n- quelles variables ont un impact positif (rouge) ou n√©gatif (bleu) sur la pr√©diction d'appartenance √† une classe,   \n- l'amplitude de cet impact.")
                st.write('')
                st.write('')
                j=df2.loc[index].index_shape
                k = 0
                liste = ['Cat√©gorie A', 'Cat√©gorie B', 'Cat√©gorie C', 'Cat√©gorie D','Cat√©gorie E','Cat√©gorie F','Cat√©gorie G']
                for k in range(0,7,1):
                    st.caption(liste[k])
                    st_shap(shap.force_plot(explainer[k], shap_values[k][j,:], X_test.iloc[j,:]))
                    k = k+1


#_______________________________________________________________________________________________________
#
#                                   Page 6 : Pr√©dictions: Algorithme 'CO‚ÇÇ Predict' 
#_______________________________________________________________________________________________________

# Chargement des mod√®les:
lr_es = load('lr_es.joblib')
lr_go = load('lr_go.joblib')
sfm_es = load('sfm_es.joblib')
sfm_go = load('sfm_go.joblib')


#explainer:
explainer_rf_opt = load('explainer_rf_opt2.joblib')
#explainer_svm_opt = load('explainer_svm.joblib')
explainer_knn_opt = load('explainer_knn_opt.joblib')

#explainer_expected_values:
explainer_rf_opt_exp_val = load('explainer_rf_opt.expected_value.joblib')
explainer_knn_opt_exp_val = load('explainer_knn.expected_value.joblib')
explainer_svm_opt_exp_val = load('explainer_svm_opt.expected_value.joblib')


# ANIMATION STREAMLIT------------------------------------------------------------------------------------------------------------------------------

if page == pages[6]:
    st.write("#### Pr√©dictions: Algorithme 'CO‚ÇÇ Predict'")
    st.markdown("- Utilisez notre algorithme **'CO‚ÇÇ Predict'** pour pr√©dire les rejets de CO‚ÇÇ et la cat√©gorie de pollution de votre v√©hicule.  \n- Les algoritmes de r√©gression et de classification √©tant diff√©rents, il se peut qu'une pr√©vision de rejets de CO‚ÇÇ par r√©gression ne correspondent pas √† la cat√©gorie d'√©mission pr√©dite par un algoritme de classification.  \n- Choisissez la valeur de chaque variable avec coh√©rence et prenez du recul sur l'interpr√©tation.")
    st.write('___')
    st.write("###### Configurez votre v√©hicule: üëá")
    st.write('')


    c1, c2, c3 = st.columns((1,1,1))
    with c1:
        marque = st.selectbox("Marque:", df.Marque.unique())
        
        carburant = st.selectbox("Carburant:",  ["Essence", "Diesel"])
        if carburant == "Essence":
            carburant = "ES"
            
        else:
            carburant = "GO"
            
        carrosserie = st.selectbox("Carrosserie:", df.Carrosserie.unique())
        
    with c2:
        # Donn√©es:       
        puissance = st.slider('Puissance (CV):', 40, 540, value = 150)
        
        masse = st.slider('Masse (kg):', 900, 3000, value = 1500)  
        
        

        
    with c3:
        boite = st.selectbox("Boite:", ["Manuelle", "Automatique"])
        if boite == "Manuelle":
            boite = "M"
            
        else:
            boite = "A"
            
        gamme = st.selectbox("Gamme:", df.gamme2.unique())
        
        #Cr√©ation du dataframe avec ces nouvelles donn√©es:    
        dic = {'Marque': marque,
               'Carburant': carburant,
               'puiss_max': puissance, 
               'masse_ordma_min': masse,
               'Carrosserie': carrosserie,
               'boite': boite,
               'gamme2': gamme}
                    
        new_car = pd.DataFrame(data = dic, index = ['0'])
        
        new_df = df_class.append(dic, ignore_index=True)
        
    st.write(' ')
    if carburant == "ES":
        st.write("L'algorithme a √©t√© entrain√© sur un dataset dont les limites pour les variables 'Puissance' et 'Masse' des v√©hicules essence sont:   \n- 44 CV < puissance < 540 CV,   \n- 825 kg < masse < 3115 kg")
    
    if carburant == "GO":
        st.write("L'algorithme a √©t√© entrain√© sur un dataset dont les limites pour les variables 'Puissance' et 'Masse' des v√©hicules diesel sont:   \n- 40 CV < puissance < 280 CV,   \n- 845 kg < masse < 2680 kg")

  
    st.write('___')


    reg_predict, classif_predict, SHAP = st.columns((0.45,0.45,1.1))
    with reg_predict:
        #pr√©proceesing r√©gression:  
        dic_reg = {'Marque': marque,
                   'puiss_max': puissance, 
                   'masse_ordma_min': masse,
                   'Carrosserie': carrosserie,
                   'boite': boite,
                   'gamme2': gamme}
        
        if carburant == 'ES':
            new_car = new_car.drop(['Carburant'], axis = 1)
            df_ES = df[df.Carburant =='ES']
            df_ES = df_ES.drop(['Carburant', 'CO2', 'Cat_CO2'], axis = 1)
            df_ES = df_ES.append(dic_reg, ignore_index=True)
            
                
        # On s√©pare les variables num√©riques et cat√©gorielles
            var_num_new = df_ES.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
            var_cat_new = df_ES.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles 
        
        # Lab√©lisation des variables cat√©gorielles par labelencoder:
            labelencoder = LabelEncoder()
            var_cat_num = var_cat_new.apply(labelencoder.fit_transform)
        
            data_ES = var_num_new.join(var_cat_num)
            
            new_car_num = data_ES.loc[[2057]]
            data_num = data_ES.drop([2057], axis = 0)    
                
            target = pd.DataFrame(target_es, index = data_num.index)
        
        else:
            new_car = new_car.drop(['Carburant'], axis = 1)
            df_GO = df[df.Carburant =='GO']
            df_GO = df_GO.drop(['Carburant', 'CO2', 'Cat_CO2'], axis = 1)
            df_GO = df_GO.append(dic_reg, ignore_index=True)
                        
            # On s√©pare les variables num√©riques et cat√©gorielles
            var_num_new = df_GO.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
            var_cat_new = df_GO.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles 
            
            # Lab√©lisation des variables cat√©gorielles par labelencoder:
            labelencoder = LabelEncoder()
            var_cat_num = var_cat_new.apply(labelencoder.fit_transform)
            
            data_GO = var_num_new.join(var_cat_num)
            
            new_car_num = data_GO.loc[[2961]]
            data_num = data_GO.drop([2961], axis = 0)    
                    
            target = pd.DataFrame(target_go, index = data_num.index)
            
            
        X_train, X_test, y_train, y_test = train_test_split(data_num, target, random_state = 123, test_size = 0.2)
    
        #Standardisation des valeurs num√©riques + variables 'Marque' (beaucoup de cat√©gories (>10)):
        cols = ['puiss_max', 'masse_ordma_min', 'Marque']
        sc = StandardScaler()
        X_train[cols] = sc.fit_transform(X_train[cols])
        new_car_num[cols] = sc.transform(new_car_num[cols])
    

    
       
        if carburant == 'ES':
            st.markdown("###### S√©lectionnez l'algorithme: üëá")
            choix_lr_pred = st.radio(" ",
                                     ["Mod√®le g√©n√©ral Essence",
                                      "Mod√®le affin√© Essence"],
                                     horizontal=False)
            
            if choix_lr_pred == "Mod√®le g√©n√©ral Essence":
                model = lr_es
            if choix_lr_pred == "Mod√®le affin√© Essence":
                model = sfm_es
                new_car_num = new_car_num[['puiss_max','masse_ordma_min']]
        
        else:
            st.markdown("###### S√©lectionnez l'algorithme de r√©gression: üëá")
            choix_lr_pred_go = st.radio(" ",
                                        ["Mod√®le g√©n√©ral Diesel",
                                         "Mod√®le affin√© Diesel"],
                                        horizontal=False)

            if choix_lr_pred_go == "Mod√®le g√©n√©ral Diesel":
                model = lr_go
            if choix_lr_pred_go == "Mod√®le affin√© Diesel":
                model = sfm_go
                new_car_num = new_car_num[['masse_ordma_min']]
    
        new_car_pred_lr = model.predict(new_car_num)
        pred_CO2 = new_car_pred_lr[0]
        st.write('')
        st.write('')
        st.write('')
        st.write('')
        st.write('Pr√©dictions des rejets de CO‚ÇÇ (en g/km):') 
        st.subheader(np.round(pred_CO2,0))    
        
        
        
    with classif_predict:
        #pr√©proceesing classification:    
        # On s√©pare les variables num√©riques et cat√©gorielles
        var_num_new = new_df.select_dtypes(exclude = 'object') # On r√©cup√®re les variables num√©riques
        var_cat_new = new_df.select_dtypes(include = 'object') # On r√©cup√®re les variables cat√©gorielles
        
        var_cat_num1 = pd.get_dummies(var_cat_new, drop_first = True)
            
        new_df_enc = var_num_new.join(var_cat_num1)
        
        
        new_car_enc = new_df_enc.loc[[5018]]
        new_df_enc = new_df_enc.drop([5018], axis = 0)
        
        X_train, X_test, y_train, y_test = train_test_split(new_df_enc, target_class,
                                                            test_size = 0.25,
                                                            random_state = 2,
                                                            stratify = target_class)
        # Les variables num√©riques doivent √™tre standardis√©es
        cols = ['puiss_max', 'masse_ordma_min']
        sc = StandardScaler()
        X_train[cols] = sc.fit_transform(X_train[cols])
        new_car_enc[cols] = sc.transform(new_car_enc[cols])
        
        #Pr√©dictions:
        st.markdown("###### S√©lectionnez l'algorithme de classification: üëá")
        choix_model_pred = st.radio("",
                                    ["Random Forest optimis√© (= le meilleur)",
                                     "SVM optimis√©",
                                     "KNN optimis√©"],
                                    horizontal=False)
        
        if choix_model_pred == "Random Forest optimis√© (= le meilleur)":
            model = model_rf_opt
            explainer = explainer_rf_opt
            expected_values = explainer_rf_opt_exp_val
            message = "###### Analysez les graphiques suivants pour comprendre les raisons ayant pouss√© 'CO‚ÇÇ Predict' √† classer votre v√©hicule dans cette cat√©gorie: üëá"
        if choix_model_pred == "SVM optimis√©":
            model = model_svm_opt
            message = "A cause de temps de calcul trop longs, il n'est pas possible d'afficher les force_plots du mod√®le SVM via cette application."
            expected_values = explainer_svm_opt_exp_val
        if choix_model_pred == "KNN optimis√©":
            model = model_knn_opt
            explainer = explainer_knn_opt
            expected_values = explainer_knn_opt_exp_val
            message = "###### Analysez les graphiques suivants pour comprendre les raisons ayant pouss√© 'CO‚ÇÇ Predict' √† classer votre v√©hicule dans cette cat√©gorie: üëá"
    
        new_car_pred_cat = model.predict(new_car_enc)
        pred_CO2_cat = new_car_pred_cat[0]
        st.write('')
        st.write('')
        st.write('')
        st.write("Pr√©diction de la cat√©gorie d'√©mission de CO‚ÇÇ:")
        st.subheader(pred_CO2_cat)
        
    
        from PIL import Image
        image_pred = Image.open('etiquette-energie-voiture.jpg')
        st.image(image_pred,caption='', width=300)
        
    with SHAP:
        
        
        st.write(message)
        st.write('')
        st.write('')
        if choix_model_pred == "Random Forest optimis√© (= le meilleur)" or choix_model_pred == "KNN optimis√©":
            shap_values = explainer.shap_values(new_car_enc)
            k = 0
            liste = ['Cat√©gorie A', 'Cat√©gorie B', 'Cat√©gorie C', 'Cat√©gorie D','Cat√©gorie E','Cat√©gorie F','Cat√©gorie G']
            for k in range(0,7,1):
                st.caption(liste[k])
                st_shap(shap.force_plot(expected_values[k], shap_values[k][0], new_car_enc.iloc[0,:]))
                k = k+1




# ANIMATION STREAMLIT------------------------------------------------------------------------------------------------------------------------------

if page == pages[7]:
    st.write("#### Conclusion")
    st.write("Les algorithmes, aussi puissants soient-ils, ne nous donnent qu‚Äôun r√©sultat de pr√©diction, ce qui suscite beaucoup de questions sur leurs utilisations (√©thique, juridique, bonne prise de d√©cision, etc‚Ä¶). Comment avoir r√©ellement confiance en ces pr√©dictions ? Les m√©thodes d‚Äôinterpr√©tabilit√© et d‚Äôexplicabilit√© de ces mod√®les, telles que SHAP ou LIME, r√©pondent, en partie, √† ces interrogations.  Elles apportent confiance et transparence. Les mod√®les de Machine Learning (ML) et Deep Learning (DL) sont souvent d√©crits comme des ¬´ bo√Ætes noires ¬ª. Ces m√©thodes allument la lumi√®re de ces bo√Ætes noires. Comprendre le fonctionnement d‚Äôun mod√®le dans sa globalit√© et les causes d‚Äôune pr√©diction constituent une √©tape cruciale dans l‚Äôacceptation, le d√©ploiement, l‚Äôutilisation, la connaissance des limites  des mod√®les de ML et DL. L‚Äôinterpr√©tabilit√© apporte du sens √† la mod√©lisation.")
    st.write("Cependant, ces outils ont aussi des inconv√©nients. Pour la m√©thode SHAP utilis√©e dans ce projet, le temps de calcul de cet algorithme sur le jeu de test (1255 observations ‚Äì 66  variables) pouvait atteindre plus de 20h pour les mod√®les SVM et KNN!  Cette contrainte a √©t√© compens√©e en √©chantillonnant 75 observations, d√©gradant malheureusement la qualit√© de l‚Äôinterpr√©tabilit√©. De plus, l‚Äôinterpr√©tabilit√© d‚Äôune nouvelle observation nous oblige √† relancer ces calculs, couteux en temps et √©nergie.")
    st.write("Bien que la m√©thode SHAP constitue une aide indispensable √† la prise de d√©cision, celle-ci n‚Äô√©chappe pas aux compromis.")
    st.write("Plus g√©n√©ralement, il faut pr√™ter une attention particuli√®re √† la valeur de chaque variable choisie pour calculer une pr√©diction. Un mod√®le calculera, affichera une pr√©diction quelles que soient ses entr√©es, vous montrera les graphiques d‚Äôinterpr√©tabilit√©. Il est par exemple possible de calculer une pr√©diction de rejets de CO2 pour une Bentley, minibus, de 70 CV, 2900 kg, √† moteur essence, en boite manuelle et de gamme luxe. M√™me si l‚Äô√©vocation de ce v√©hicule pr√™te √† sourire, ‚ÄòCO2 Predict‚Äô calcule les √©missions, la cat√©gorie de pollution et vous donne les raisons de ce classement. Or, ce type de v√©hicule n‚Äôa aucun sens. La responsabilit√© de l‚Äôutilisateur tient notamment dans la coh√©rence des valeurs de chaque variable. Le r√©sultat d‚Äôune pr√©diction n‚Äôexclut pas le bon sens ! La place de l‚Äôhumain reste centrale dans cette univers ‚Äòdata‚Äô.")
    st.write("Ce projet de pr√©diction des rejets de CO2 nous a permis de mettre moins en avant une qualit√© de pr√©diction par l‚Äôutilisation de mod√®les de ML qu‚Äôune pr√©sentation, non exhaustive, de l‚Äôutilit√© de l‚Äôinterpr√©tabilit√© de ces mod√®les.")

